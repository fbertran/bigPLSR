<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Double RKHS PLS (rkhs_xy): Theory and Usage ‚Ä¢ bigPLSR</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Double RKHS PLS (rkhs_xy): Theory and Usage">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">bigPLSR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.7.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/bigPLSR-auto-selection.html">Automatic Algorithm Selection in bigPLSR</a></li>
    <li><a class="dropdown-item" href="../articles/bigPLSR-kpls-streaming.html">Streaming Kernel PLS in bigPLSR: XX^T and Column-Chunked Variants</a></li>
    <li><a class="dropdown-item" href="../articles/bootstrap-strategies.html">Bootstrap strategies for bigPLSR</a></li>
    <li><a class="dropdown-item" href="../articles/cross-validation-ic.html">Cross-validation and Information Criteria in bigPLSR</a></li>
    <li><a class="dropdown-item" href="../articles/double-rkhs-pls.html">Double RKHS PLS (rkhs_xy): Theory and Usage</a></li>
    <li><a class="dropdown-item" href="../articles/kf-pls.html">KF-PLS: Streaming PLS with Kalman-style updates</a></li>
    <li><a class="dropdown-item" href="../articles/klogitpls.html">Kernel Logistic PLS</a></li>
    <li><a class="dropdown-item" href="../articles/kpls_review.html">Kernel and Streaming PLS Methods in bigPLSR</a></li>
    <li><a class="dropdown-item" href="../articles/plotting-guide.html">Visualising PLS Fits with bigPLSR</a></li>
    <li><a class="dropdown-item" href="../articles/pls1-benchmark.html">Benchmarking PLS1 Implementations</a></li>
    <li><a class="dropdown-item" href="../articles/pls2-benchmark.html">Benchmarking PLS2 Implementations</a></li>
    <li><a class="dropdown-item" href="../articles/rkhs-overview.html">RKHS-based Algorithms in bigPLSR</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/fbertran/bigPLSR/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Double RKHS PLS (rkhs_xy): Theory and Usage</h1>
                        <h4 data-toc-skip class="author">Fr√©d√©ric
Bertrand</h4>
            <address class="author_afil">
      Cedric, Cnam,
Paris<br><a class="author_email" href="mailto:#"></a><a href="mailto:frederic.bertrand@lecnam.net" class="email">frederic.bertrand@lecnam.net</a>
      </address>
                  
            <h4 data-toc-skip class="date">2025-11-11</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/fbertran/bigPLSR/blob/HEAD/vignettes/double-rkhs-pls.Rmd" class="external-link"><code>vignettes/double-rkhs-pls.Rmd</code></a></small>
      <div class="d-none name"><code>double-rkhs-pls.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<p>We implement a <strong>double RKHS</strong> variant of PLS, where
both the input and the output spaces are endowed with reproducing
kernels:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>X</mi></msub><mo>‚àà</mo><msup><mi>‚Ñù</mi><mrow><mi>n</mi><mo>√ó</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">K_X \in \mathbb{R}^{n\times n}</annotation></semantics></math>
with entries
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>K</mi><mi>X</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>k</mi><mi>X</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">[K_X]_{ij} = k_X(x_i, x_j)</annotation></semantics></math>,</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>Y</mi></msub><mo>‚àà</mo><msup><mi>‚Ñù</mi><mrow><mi>n</mi><mo>√ó</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">K_Y \in \mathbb{R}^{n\times n}</annotation></semantics></math>
with entries
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>K</mi><mi>Y</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>k</mi><mi>Y</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">[K_Y]_{ij} = k_Y(y_i, y_j)</annotation></semantics></math>.</li>
</ul>
<p>We use centered Grams
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>K</mi><mo accent="true">ÃÉ</mo></mover><mi>X</mi></msub><mo>=</mo><mi>H</mi><msub><mi>K</mi><mi>X</mi></msub><mi>H</mi></mrow><annotation encoding="application/x-tex">\tilde K_X = H K_X H</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>K</mi><mo accent="true">ÃÉ</mo></mover><mi>Y</mi></msub><mo>=</mo><mi>H</mi><msub><mi>K</mi><mi>Y</mi></msub><mi>H</mi></mrow><annotation encoding="application/x-tex">\tilde K_Y = H K_Y H</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>=</mo><mi>I</mi><mo>‚àí</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mn>ùüè</mn><msup><mn>ùüè</mn><mi>‚ä§</mi></msup></mrow><annotation encoding="application/x-tex">H = I - \frac{1}{n}\mathbf{1}\mathbf{1}^\top</annotation></semantics></math>.</p>
<div class="section level3">
<h3 id="operator-and-latent-directions">Operator and Latent Directions<a class="anchor" aria-label="anchor" href="#operator-and-latent-directions"></a>
</h3>
<p>Following the spirit of <em>Kernel PLS Regression II</em> (IEEE
TNNLS, 2019), we avoid explicit square roots and form the <strong>SPD
surrogate operator</strong>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>‚Ñ≥</mi><mspace width="0.167em"></mspace><mi>v</mi><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>K</mi><mi>X</mi></msub><mo>+</mo><msub><mi>Œª</mi><mi>x</mi></msub><mi>I</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>‚àí</mi><mn>1</mn></mrow></msup><mspace width="0.278em"></mspace><msub><mi>K</mi><mi>X</mi></msub><mspace width="0.278em"></mspace><msub><mi>K</mi><mi>Y</mi></msub><mspace width="0.278em"></mspace><msub><mi>K</mi><mi>X</mi></msub><mspace width="0.278em"></mspace><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>K</mi><mi>X</mi></msub><mo>+</mo><msub><mi>Œª</mi><mi>x</mi></msub><mi>I</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>‚àí</mi><mn>1</mn></mrow></msup><mspace width="0.167em"></mspace><mi>v</mi><mo>,</mo></mrow><annotation encoding="application/x-tex">
\mathcal{M} \, v
= (K_X+\lambda_x I)^{-1} \; K_X \; K_Y \; K_X \; (K_X+\lambda_x I)^{-1} \, v,
</annotation></semantics></math> with small ridge
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œª</mi><mi>x</mi></msub><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda_x &gt; 0</annotation></semantics></math>
for stability. We compute the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
orthonormal latent directions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>t</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>t</mi><mi>A</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">T = [t_1,\dots,t_A]</annotation></semantics></math>
via power iteration with Gram‚ÄìSchmidt orthogonalization on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚Ñ≥</mi><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math>.</p>
<p>We then solve a <strong>small</strong> regression in the latent
space:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>T</mi><mi>‚ä§</mi></msup><mi>T</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>‚àí</mi><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>T</mi><mi>‚ä§</mi></msup><mover><mi>Y</mi><mo accent="true">ÃÉ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="2.0em"></mspace><mover><mi>Y</mi><mo accent="true">ÃÉ</mo></mover><mo>=</mo><mi>Y</mi><mo>‚àí</mo><mn>ùüè</mn><msup><mover><mi>y</mi><mo accent="true">‚Äæ</mo></mover><mi>‚ä§</mi></msup><mo>,</mo></mrow><annotation encoding="application/x-tex">
C = (T^\top T)^{-1} (T^\top \tilde Y),
\qquad \tilde Y = Y - \mathbf{1} \bar y^\top,
</annotation></semantics></math> and form dual coefficients
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ±</mi><mspace width="0.278em"></mspace><mo>=</mo><mspace width="0.278em"></mspace><mi>U</mi><mspace width="0.167em"></mspace><mi>C</mi><mo>,</mo><mspace width="2.0em"></mspace><mi>U</mi><mspace width="0.278em"></mspace><mo>=</mo><mspace width="0.278em"></mspace><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>K</mi><mi>X</mi></msub><mo>+</mo><msub><mi>Œª</mi><mi>x</mi></msub><mi>I</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>‚àí</mi><mn>1</mn></mrow></msup><mi>T</mi><mo>,</mo></mrow><annotation encoding="application/x-tex">
\alpha \;=\; U \, C, \qquad U \;=\; (K_X+\lambda_x I)^{-1} T,
</annotation></semantics></math> so that training predictions satisfy
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>Y</mi><mo accent="true">ÃÇ</mo></mover><mspace width="0.278em"></mspace><mo>=</mo><mspace width="0.278em"></mspace><msub><mover><mi>K</mi><mo accent="true">ÃÉ</mo></mover><mi>X</mi></msub><mspace width="0.167em"></mspace><mi>Œ±</mi><mo>+</mo><mn>ùüè</mn><mspace width="0.167em"></mspace><msup><mover><mi>y</mi><mo accent="true">‚Äæ</mo></mover><mi>‚ä§</mi></msup><mi>.</mi></mrow><annotation encoding="application/x-tex">
\hat Y \;=\; \tilde K_X \, \alpha + \mathbf{1}\,\bar y^\top .
</annotation></semantics></math></p>
</div>
<div class="section level3">
<h3 id="centering-for-prediction">Centering for Prediction<a class="anchor" aria-label="anchor" href="#centering-for-prediction"></a>
</h3>
<p>Given new inputs <span class="math inline">$X_\*$</span>, define the
<strong>cross-Gram</strong> <span class="math display">$$
K_\* = K(X_\*, X) .
$$</span> To apply training centering to <span class="math inline">$K_\*$</span>, use <span class="math display">$$
\tilde K_\* \;=\; K_\* \;-\; \mathbf{1}\, \bar k_X^\top \;-\; \bar k_\*
\mathbf{1}^\top \;+\; \mu_X,
$$</span> where: -
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>k</mi><mo accent="true">‚Äæ</mo></mover><mi>X</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msup><mn>ùüè</mn><mi>‚ä§</mi></msup><msub><mi>K</mi><mi>X</mi></msub></mrow><annotation encoding="application/x-tex">\bar k_X = \frac{1}{n}\mathbf{1}^\top K_X</annotation></semantics></math>
is the <strong>column mean</strong> vector for the (uncentered) training
Gram, -
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œº</mi><mi>X</mi></msub><mo>=</mo><mfrac><mn>1</mn><msup><mi>n</mi><mn>2</mn></msup></mfrac><msup><mn>ùüè</mn><mi>‚ä§</mi></msup><msub><mi>K</mi><mi>X</mi></msub><mn>ùüè</mn></mrow><annotation encoding="application/x-tex">\mu_X = \frac{1}{n^2} \mathbf{1}^\top K_X \mathbf{1}</annotation></semantics></math>
is its <strong>grand mean</strong>, - <span class="math inline">$\bar
k_\*$</span> is the <strong>row mean</strong> of <span class="math inline">$K_\*$</span> (computed at prediction time).</p>
<p>Predictions then follow the familiar dual form: <span class="math display">$$
\hat Y_\* \;=\; \tilde K_\* \, \alpha + \mathbf{1}_\* \, \bar y^\top .
$$</span></p>
</div>
<div class="section level3">
<h3 id="practical-notes">Practical Notes<a class="anchor" aria-label="anchor" href="#practical-notes"></a>
</h3>
<ul>
<li>Choose
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>k</mi><mi>X</mi></msub><annotation encoding="application/x-tex">k_X</annotation></semantics></math>
(e.g., RBF) to reflect <strong>nonlinear structure</strong> in inputs. A
linear
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>k</mi><mi>Y</mi></msub><annotation encoding="application/x-tex">k_Y</annotation></semantics></math>
already produces numeric outputs in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>‚Ñù</mi><mi>m</mi></msup><annotation encoding="application/x-tex">\mathbb{R}^m</annotation></semantics></math>.</li>
<li>The ridge terms
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œª</mi><mi>x</mi></msub><mo>,</mo><msub><mi>Œª</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_x, \lambda_y</annotation></semantics></math>
stabilize inversions and dampen numerical noise.</li>
<li>With <code>algorithm = "rkhs_xy"</code>, the package returns:
<ul>
<li>
<code>dual_coef</code>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mi>Œ±</mi></mrow><annotation encoding="application/x-tex">=\alpha</annotation></semantics></math>,</li>
<li>
<code>scores</code>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">=T</annotation></semantics></math>
(approximately orthonormal),</li>
<li>
<code>intercept</code>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mover><mi>y</mi><mo accent="true">‚Äæ</mo></mover></mrow><annotation encoding="application/x-tex">=\bar y</annotation></semantics></math>,</li>
<li>and uses the centered cross-kernel formula above in
<code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code>.</li>
</ul>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="minimal-example">Minimal Example<a class="anchor" aria-label="anchor" href="#minimal-example"></a>
</h3>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://fbertran.github.io/bigPLSR/">bigPLSR</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">60</span>; <span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">6</span>; <span class="va">m</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.4</span> <span class="op">*</span> <span class="va">X</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">^</span><span class="fl">2</span>,</span>
<span>           <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">cos</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span><span class="op">)</span> <span class="op">-</span> <span class="fl">0.3</span> <span class="op">*</span> <span class="va">X</span><span class="op">[</span>,<span class="fl">4</span><span class="op">]</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">m</span>, sd<span class="op">=</span><span class="fl">.05</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">m</span><span class="op">)</span></span>
<span></span>
<span><span class="va">op</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span></span>
<span>  bigPLSR.rkhs_xy.kernel_x <span class="op">=</span> <span class="st">"rbf"</span>,</span>
<span>  bigPLSR.rkhs_xy.gamma_x  <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  bigPLSR.rkhs_xy.kernel_y <span class="op">=</span> <span class="st">"linear"</span>,</span>
<span>  bigPLSR.rkhs_xy.lambda_x <span class="op">=</span> <span class="fl">1e-6</span>,</span>
<span>  bigPLSR.rkhs_xy.lambda_y <span class="op">=</span> <span class="fl">1e-6</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/on.exit.html" class="external-link">on.exit</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span><span class="va">op</span><span class="op">)</span>, add <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pls_fit.html">pls_fit</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">Y</span>, ncomp <span class="op">=</span> <span class="fl">3</span>, algorithm <span class="op">=</span> <span class="st">"rkhs_xy"</span>, backend <span class="op">=</span> <span class="st">"arma"</span><span class="op">)</span></span>
<span><span class="va">Yhat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">X</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">Y</span> <span class="op">-</span> <span class="va">Yhat</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2.619847e-12</span></span></code></pre>
<p>References ‚Ä¢ Rosipal &amp; Trejo (2001) Kernel Partial Least Squares
Regression in Reproducing Kernel Hilbert Space. JMLR 2:97‚Äì123. <a href="doi:10.5555/944733.944741" class="uri">doi:10.5555/944733.944741</a>. ‚Ä¢ Kernel PLS Regression II:
Kernel Partial Least Squares Regression by Projecting Both Independent
and Dependent Variables into Reproducing Kernel Hilbert Space. IEEE
TNNLS (2019). <a href="doi:10.1109/TNNLS.2019.2932014" class="uri">doi:10.1109/TNNLS.2019.2932014</a>.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Frederic Bertrand, Myriam Maumy.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
