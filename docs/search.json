[{"path":"https://fbertran.github.io/bigPLSR/articles/pls1-benchmark.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Benchmarking PLS1 Implementations","text":"vignette illustrates benchmark dense streaming implementations provided single-response partial least squares regression (PLS1). dense implementation (pls1_dense) copies predictor matrix memory therefore preferred whole dataset fits RAM. streaming implementation (pls1_stream) iterates data blocks, enabling analyses larger--memory workloads.","code":""},{"path":"https://fbertran.github.io/bigPLSR/articles/pls1-benchmark.html","id":"simulated-data","dir":"Articles","previous_headings":"","what":"Simulated data","title":"Benchmarking PLS1 Implementations","text":"generate moderately sized synthetic datasets low dimensional latent structure. predictors stored bigmemory::big.matrix can reused without additional copies benchmarks. example n=4000 en p=50","code":"n <- 1000 p <- 50 ncomp <- 5  X <- bigmemory::big.matrix(nrow = n, ncol = p, type = \"double\") X[,] <- matrix(rnorm(n * p), nrow = n)  true_beta <- matrix(rnorm(p), ncol = 1) y_vec <- as.vector(scale(X[,] %*% true_beta + rnorm(n)))  y <- bigmemory::big.matrix(nrow = n, ncol = 1, type = \"double\") y[,] <- y_vec  X[1:6, 1:6] #>             [,1]        [,2]       [,3]        [,4]       [,5]       [,6] #> [1,] -0.56047565 -0.99579872 -0.5116037 -0.15030748  0.1965498 -0.4941739 #> [2,] -0.23017749 -1.03995504  0.2369379 -0.32775713  0.6501132  1.1275935 #> [3,]  1.55870831 -0.01798024 -0.5415892 -1.44816529  0.6710042 -1.1469495 #> [4,]  0.07050839 -0.13217513  1.2192276 -0.69728458 -1.2841578  1.4810186 #> [5,]  0.12928774 -2.54934277  0.1741359  2.59849023 -2.0261096  0.9161912 #> [6,]  1.71506499  1.04057346 -0.6152683 -0.03741501  2.2053261  0.3351310 y[1:6,] #> [1] -1.30750385 -0.31942974  0.78534055  0.95482632 -0.64407070 -0.04507161"},{"path":"https://fbertran.github.io/bigPLSR/articles/pls1-benchmark.html","id":"benchmark-results","dir":"Articles","previous_headings":"","what":"Benchmark results","title":"Benchmarking PLS1 Implementations","text":"bench package provides convenient framework compare runtime characteristics solvers. following benchmark uses chunk size 1024 rows streaming variant, offers good trade-speed memory usage dataset size.","code":"bench_res_simpls <- press(   n = c(500, 1000, 5000),   p = c(100, 500, 1000),   {     ncomp = 5     rep = 1     algorithm = \"simpls\"     X <- bigmemory::big.matrix(nrow = n, ncol = p, type = \"double\")     X[,] <- matrix(rnorm(n * p), nrow = n)      true_beta <- matrix(rnorm(p), ncol = 1)     y_vec <- as.vector(scale(X[,] %*% true_beta + rnorm(n)))      y <- bigmemory::big.matrix(nrow = n, ncol = 1, type = \"double\")     y[,] <- y_vec     bench::mark(       dense = pls1_dense(X, y_vec, ncomp = ncomp, algorithm = algorithm),       streaming = pls1_stream(X, y_vec, ncomp = ncomp, chunk_size = 1024L,                                algorithm = algorithm),       dense_a = pls1_dense_a(X, y, ncomp = ncomp, algorithm = algorithm),       streaming_a = pls1_stream_a(X, y, ncomp = ncomp, chunk_size = 1024L,                                    algorithm = algorithm),       dense_ya = pls1_dense_ya(X, y, ncomp = ncomp, algorithm = algorithm),       streaming_ya = pls1_stream_ya(X, y, ncomp = ncomp, chunk_size = 1024L,                                      algorithm = algorithm),       iterations = 10,       check = FALSE     )     } ) bench_res_nipals <- press(   n = c(500, 1000, 5000),   p = c(100, 500, 1000),   {     ncomp = 5     rep = 1     algorithm = \"nipals\"     X <- bigmemory::big.matrix(nrow = n, ncol = p, type = \"double\")     X[,] <- matrix(rnorm(n * p), nrow = n)      true_beta <- matrix(rnorm(p), ncol = 1)     y_vec <- as.vector(scale(X[,] %*% true_beta + rnorm(n)))      y <- bigmemory::big.matrix(nrow = n, ncol = 1, type = \"double\")     y[,] <- y_vec     bench::mark(       dense = pls1_dense(X, y_vec, ncomp = ncomp, algorithm = algorithm),       streaming = pls1_stream(X, y_vec, ncomp = ncomp, chunk_size = 1024L,                                algorithm = algorithm),       dense_a = pls1_dense_a(X, y, ncomp = ncomp, algorithm = algorithm),       streaming_a = pls1_stream_a(X, y, ncomp = ncomp, chunk_size = 1024L,                                    algorithm = algorithm),       dense_ya = pls1_dense_ya(X, y, ncomp = ncomp, algorithm = algorithm),       streaming_ya = pls1_stream_ya(X, y, ncomp = ncomp, chunk_size = 1024L,                                      algorithm = algorithm),       iterations = 10,       check = FALSE     )     } )"},{"path":"https://fbertran.github.io/bigPLSR/articles/pls1-benchmark.html","id":"interpreting-the-output","dir":"Articles","previous_headings":"","what":"Interpreting the output","title":"Benchmarking PLS1 Implementations","text":"table summarises timing memory footprint solver. practice can adjust number components, chunk size data generation process mimic workload. working file-backed matrices streaming solver often viable option, whereas dense solver remains fastest choice datasets comfortably fit memory.","code":"bench_res_simpls #> # A tibble: 54 × 8 #>    expression       n     p      min   median `itr/sec` mem_alloc `gc/sec` #>    <bch:expr>   <dbl> <dbl> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> #>  1 dense          500   100   5.11ms   5.28ms     189.    199.4KB     0    #>  2 streaming      500   100  26.68ms  26.74ms      37.3      49KB     0    #>  3 dense_a        500   100   4.67ms   4.71ms     212.     42.1KB     0    #>  4 streaming_a    500   100  26.25ms  26.38ms      37.7    47.7KB     0    #>  5 dense_ya       500   100   4.67ms   4.71ms     212.     43.5KB     0    #>  6 streaming_ya   500   100  26.22ms  26.32ms      37.9    43.8KB     0    #>  7 dense         1000   100   8.57ms   8.73ms     114.     18.4KB     0    #>  8 streaming     1000   100  51.21ms  51.31ms      19.2    18.4KB     2.13 #>  9 dense_a       1000   100   8.23ms   8.29ms     120.     11.2KB     0    #> 10 streaming_a   1000   100  50.79ms  50.89ms      19.6    11.6KB     0    #> # ℹ 44 more rows bench_res_nipals #> # A tibble: 54 × 8 #>    expression       n     p      min   median `itr/sec` mem_alloc `gc/sec` #>    <bch:expr>   <dbl> <dbl> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> #>  1 dense          500   100   8.53ms   8.54ms     117.     34.7KB     0    #>  2 streaming      500   100   8.53ms   8.53ms     117.     34.9KB     0    #>  3 dense_a        500   100   6.56ms   6.58ms     152.     33.5KB     0    #>  4 streaming_a    500   100   3.54ms   3.54ms     281.     53.4KB     0    #>  5 dense_ya       500   100   8.55ms   8.56ms     117.     62.7KB     0    #>  6 streaming_ya   500   100   8.55ms   8.56ms     117.     35.2KB     0    #>  7 dense         1000   100  16.99ms     17ms      58.8    50.8KB     0    #>  8 streaming     1000   100  16.98ms     17ms      58.8    50.8KB     6.53 #>  9 dense_a       1000   100  13.04ms  13.07ms      72.9    49.5KB     0    #> 10 streaming_a   1000   100   7.08ms   7.13ms     138.       89KB     0    #> # ℹ 44 more rows plot(bench_res_simpls, type=\"jitter\") plot(bench_res_nipals, type=\"jitter\") plot(bench_res_simpls, type=\"boxplot\") plot(bench_res_nipals, type=\"boxplot\")"},{"path":"https://fbertran.github.io/bigPLSR/articles/pls2-benchmark.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Benchmarking PLS2 Implementations","text":"package offers dense (pls2_dense) streaming (pls2_stream) solvers multi-response partial least squares regression (PLS2). vignette demonstrates benchmark variants synthetic dataset featuring three correlated response variables.","code":""},{"path":"https://fbertran.github.io/bigPLSR/articles/pls2-benchmark.html","id":"simulated-data","dir":"Articles","previous_headings":"","what":"Simulated data","title":"Benchmarking PLS2 Implementations","text":"","code":"n <- 3500 p <- 40 q <- 3 ncomp <- 4  X <- bigmemory::big.matrix(nrow = n, ncol = p, type = \"double\") X[,] <- matrix(rnorm(n * p), nrow = n)  loading_matrix <- matrix(rnorm(p * q), nrow = p) latent_scores <- matrix(rnorm(n * q), nrow = n) Y_mat <- scale(latent_scores %*% t(loading_matrix[1:q, , drop = FALSE]) + matrix(rnorm(n * q, sd = 0.5), nrow = n))  Y <- bigmemory::big.matrix(nrow = n, ncol = q, type = \"double\") Y[,] <- Y_mat  X[1:6, 1:6] #>            [,1]        [,2]       [,3]       [,4]       [,5]        [,6] #> [1,] -1.3435214 -1.26820867 -1.1037112  0.7617503 -0.7401395  0.61024868 #> [2,]  0.6217756  1.11508975 -1.2768613 -1.1255784 -0.6586119  0.10081629 #> [3,]  0.8008747 -0.75753597  0.3151891 -0.2539973  1.0197950  0.19342423 #> [4,] -1.3888924  0.04744551 -0.1255208  0.2758486  1.2427898  0.26696049 #> [5,] -0.7143569  0.42990602 -1.0605240  1.5142303 -0.2104338  0.01490636 #> [6,] -0.3240611  1.76766712 -0.8403403 -0.5756483  1.0435582 -0.53748062 Y[1:6, 1:min(6,q)] #>             [,1]       [,2]        [,3] #> [1,]  0.04209719  0.1434869  0.68332640 #> [2,]  0.62385647  1.0324674 -0.23792375 #> [3,] -0.64518653 -0.9586347  1.24808892 #> [4,] -0.73590774 -0.2234672 -0.05677271 #> [5,] -0.38412792  0.3147141 -1.03324920 #> [6,]  1.98359362  0.4768693 -0.64380685"},{"path":"https://fbertran.github.io/bigPLSR/articles/pls2-benchmark.html","id":"benchmark-results","dir":"Articles","previous_headings":"","what":"Benchmark results","title":"Benchmarking PLS2 Implementations","text":"rely bench package compare implementations. block size 1024 rows used streaming solver, balances throughput memory requirements example dataset.","code":"bench_res_q_5 <- press(   n = c(500, 1000, 5000),   p = c(100, 500, 1000),   {     ncomp = 5     rep = 1     q = 5     X <- bigmemory::big.matrix(nrow = n, ncol = p, type = \"double\")     X[,] <- matrix(rnorm(n * p), nrow = n)          loading_matrix <- matrix(rnorm(p * q), nrow = p)     latent_scores <- matrix(rnorm(n * q), nrow = n)     Y_mat <- scale(latent_scores %*% t(loading_matrix[1:q, , drop = FALSE]) + matrix(rnorm(n * q, sd = 0.5), nrow = n))          Y <- bigmemory::big.matrix(nrow = n, ncol = q, type = \"double\")     Y[,] <- Y_mat          bench::mark(       dense_simpls = pls2_dense(X, Y, ncomp = ncomp, algorithm = \"simpls\"),       dense_nipals = pls2_dense(X, Y, ncomp = ncomp, algorithm = \"nipals\"),       streaming_simpls = pls2_stream(X, Y, ncomp = ncomp, chunk_size = 1024L,                                       algorithm = \"simpls\"),       streaming_nipals = pls2_stream(X, Y, ncomp = ncomp, chunk_size = 1024L,                                       algorithm = \"nipals\"),       iterations = 10,       check = FALSE     )   } ) bench_res_q_50 <- press(   n = c(500, 1000, 5000),   p = c(100, 500, 1000),   {     ncomp = 5     rep = 1     q = 50     X <- bigmemory::big.matrix(nrow = n, ncol = p, type = \"double\")     X[,] <- matrix(rnorm(n * p), nrow = n)          loading_matrix <- matrix(rnorm(p * q), nrow = p)     latent_scores <- matrix(rnorm(n * q), nrow = n)     Y_mat <- scale(latent_scores %*% t(loading_matrix[1:q, , drop = FALSE]) + matrix(rnorm(n * q, sd = 0.5), nrow = n))          Y <- bigmemory::big.matrix(nrow = n, ncol = q, type = \"double\")     Y[,] <- Y_mat          bench::mark(       dense_simpls = pls2_dense(X, Y, ncomp = ncomp, algorithm = \"simpls\"),       dense_nipals = pls2_dense(X, Y, ncomp = ncomp, algorithm = \"nipals\"),       streaming_simpls = pls2_stream(X, Y, ncomp = ncomp, chunk_size = 1024L,                                       algorithm = \"simpls\"),       streaming_nipals = pls2_stream(X, Y, ncomp = ncomp, chunk_size = 1024L,                                       algorithm = \"nipals\"),       iterations = 10,       check = FALSE     )   } )"},{"path":"https://fbertran.github.io/bigPLSR/articles/pls2-benchmark.html","id":"interpreting-the-output","dir":"Articles","previous_headings":"","what":"Interpreting the output","title":"Benchmarking PLS2 Implementations","text":"benchmark summary reports average worst-case execution time well memory allocations. Users working file-backed matrices large datasets prefer streaming implementation, dense solver remains strong choice data comfortably fits RAM.","code":"bench_res_q_5 #> # A tibble: 36 × 8 #>    expression           n     p      min   median `itr/sec` mem_alloc `gc/sec` #>    <bch:expr>       <dbl> <dbl> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> #>  1 dense_simpls       500   100 950.22µs  958.7µs   1026.      50.5KB        0 #>  2 dense_nipals       500   100     16ms  16.07ms     62.1     36.6KB        0 #>  3 streaming_simpls   500   100   4.08ms   4.11ms    243.      31.9KB        0 #>  4 streaming_nipals   500   100 424.75ms 425.73ms      2.34    44.7KB        0 #>  5 dense_simpls      1000   100    1.9ms   2.03ms    497.      52.9KB        0 #>  6 dense_nipals      1000   100  40.01ms  40.19ms     24.8     52.9KB        0 #>  7 streaming_simpls  1000   100   8.12ms   8.13ms    123.      13.8KB        0 #>  8 streaming_nipals  1000   100 965.84ms  969.9ms      1.01    60.8KB        0 #>  9 dense_simpls      5000   100   9.73ms   9.87ms    101.     209.1KB        0 #> 10 dense_nipals      5000   100 197.99ms 198.43ms      5.00   209.1KB        0 #> # ℹ 26 more rows bench_res_q_50 #> # A tibble: 36 × 8 #>    expression           n     p      min   median `itr/sec` mem_alloc `gc/sec` #>    <bch:expr>       <dbl> <dbl> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> #>  1 dense_simpls       500   100   6.96ms   7.33ms   138.       71.6KB        0 #>  2 dense_nipals       500   100  107.6ms 107.69ms     9.28     71.6KB        0 #>  3 streaming_simpls   500   100   14.6ms  15.13ms    66.1        52KB        0 #>  4 streaming_nipals   500   100     2.8s    2.81s     0.356   114.6KB        0 #>  5 dense_simpls      1000   100  10.92ms  11.05ms    89.8      91.1KB        0 #>  6 dense_nipals      1000   100 270.61ms 277.01ms     3.52     91.1KB        0 #>  7 streaming_simpls  1000   100  25.37ms  25.38ms    39.3        52KB        0 #>  8 streaming_nipals  1000   100    7.89s     7.9s     0.126   134.2KB        0 #>  9 dense_simpls      5000   100  42.03ms  42.14ms    23.7     247.3KB        0 #> 10 dense_nipals      5000   100    1.64s    1.65s     0.607   247.3KB        0 #> # ℹ 26 more rows plot(bench_res_q_5, type=\"jitter\") plot(bench_res_q_50, type=\"jitter\") plot(bench_res_q_5, type=\"boxplot\") plot(bench_res_q_50, type=\"boxplot\")"},{"path":"https://fbertran.github.io/bigPLSR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Frederic Bertrand. Maintainer, author. Myriam Maumy. Author.","code":""},{"path":"https://fbertran.github.io/bigPLSR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Frederic Bertrand Myriam Maumy (2025). Partial Least Squares Regression Models Big Matrices, R package version 0.6.4. Maumy, M. Bertrand, F. (2023). PLS models extension big data. Conference presentation Joint Statistical Meetings (JSM 2023), Toronto, Ontario, Canada, Aug 5–10, 2023. Maumy, M. Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. Poster BioC2023: Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA, Aug 2–4, 2023. doi:10.7490/f1000research.1119546.1.","code":"@Manual{,   title = {Partial Least Squares Regression Models with Big Matrices},   author = {Frederic Bertrand and Myriam Maumy},   publisher = {manual},   year = {2025},   note = {R package version 0.6.4},   url = {https://fbertran.github.io/bigPLSR/}, } @Misc{,   title = {PLS models and their extension for big data},   author = {Myriam Maumy and Frédéric Bertrand},   year = {2023},   howpublished = {Conference presentation at the Joint Statistical Meetings (JSM 2023)},   address = {Toronto, Ontario, Canada},   note = {Aug 5–10, 2023}, } @Misc{,   title = {bigPLS: Fitting and cross-validating PLS-based Cox models to censored big data},   author = {Myriam Maumy and Frédéric Bertrand},   year = {2023},   howpublished = {Conference presentation at BioC2023: The Bioconductor Annual Conference},   address = {Dana-Farber Cancer Institute, Boston, MA, USA},   note = {Aug 2–4, 2023},   doi = {10.7490/f1000research.1119546.1},   url = {https://doi.org/10.7490/f1000research.1119546.1}, }"},{"path":[]},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"frédéric-bertrand-and-myriam-maumy","dir":"","previous_headings":"","what":"Frédéric Bertrand and Myriam Maumy","title":"Partial Least Squares Regression Models with Big Matrices","text":"bigPLSR provides fast, scalable Partial Least Squares (PLS) two execution backends: Dense (backend = \"arma\"): -memory Armadillo/BLAS speed. Big-matrix (backend = \"bigmem\"): chunked streaming bigmemory::big.matrix large data. PLS1 (single response) PLS2 (multi-response) supported. PLS2 uses SIMPLS cross-products backends numerical parity. package set CRAN-friendly: optional CBLAS fast path default. Support parallel computation GPU developed. website examples created F. Bertrand M. Maumy.","code":""},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Partial Least Squares Regression Models with Big Matrices","text":"can install released version bigPLSR CRAN : can install development version bigPLSR github :","code":"install.packages(\"bigPLSR\") devtools::install_github(\"fbertran/bigPLSR\")"},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick start","title":"Partial Least Squares Regression Models with Big Matrices","text":"","code":"library(bigPLSR)  set.seed(1) n <- 200; p <- 50 X <- matrix(rnorm(n*p), n, p) y <- X[,1]*2 - X[,2] + rnorm(n)  # Dense PLS1 (fast) fit <- pls_fit(X, y, ncomp = 3, backend = \"arma\", scores = \"r\") str(list(   coef=dim(fit$coefficients),   scores=dim(fit$scores),   ncomp=fit$ncomp ))"},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"big-matrix-pls1-with-file-backed-scores","dir":"","previous_headings":"Quick start","what":"Big-matrix PLS1 with file-backed scores","title":"Partial Least Squares Regression Models with Big Matrices","text":"","code":"options_val_before <- options(\"bigmemory.allow.dimnames\") options(bigmemory.allow.dimnames=TRUE)  bmX <- bigmemory::as.big.matrix(X) bmy <- bigmemory::as.big.matrix(matrix(y, n, 1))  tmp=tempdir() if(file.exists(paste(tmp,\"scores.desc\",sep=\"/\"))){unlink(paste(tmp,\"scores.desc\",sep=\"/\"))} if(file.exists(paste(tmp,\"scores.bin\",sep=\"/\"))){unlink(paste(tmp,\"scores.bin\",sep=\"/\"))} sink <- bigmemory::filebacked.big.matrix(   nrow=n, ncol=3, type=\"double\",   backingfile=\"scores.bin\",   backingpath=tmp,   descriptorfile=\"scores.desc\" )  fit_b <- pls_fit(   bmX, bmy, ncomp=3, backend=\"bigmem\", scores=\"big\",   scores_target=\"existing\", scores_bm=sink,   scores_colnames = c(\"t1\",\"t2\",\"t3\"),   return_scores_descriptor = TRUE )  fit_b$scores_descriptor  # big.matrix.descriptor options(bigmemory.allow.dimnames=options_val_before)"},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"pls2-multi-response","dir":"","previous_headings":"Quick start","what":"PLS2 (multi-response)","title":"Partial Least Squares Regression Models with Big Matrices","text":"","code":"set.seed(2) m <- 3 B <- matrix(rnorm(p*m), p, m) Y <- scale(X, scale = FALSE) %*% B + matrix(rnorm(n*m, sd = 0.1), n, m)  # Dense PLS2 – SIMPLS on cross-products (parity with bigmem) fit2 <- pls_fit(X, Y, ncomp = 2, backend = \"arma\", mode = \"pls2\", scores = \"none\") str(list(coef=dim(fit2$coefficients), ncomp=fit2$ncomp))"},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"api","dir":"","previous_headings":"","what":"API","title":"Partial Least Squares Regression Models with Big Matrices","text":"Auto selection backend = \"auto\" → \"bigmem\" X big.matrix (descriptor), else \"arma\". mode = \"auto\" → \"pls1\" y one column, else \"pls2\". Return values PLS1: coefficients (p), intercept (scalar), x_weights, x_loadings, y_loadings, scores (optional), x_means, y_mean, ncomp. PLS2: coefficients (p×m), intercept (length m), x_weights (p×ncomp), x_loadings (p×ncomp), y_loadings (m×ncomp), scores (optional), x_means, y_means, ncomp.","code":"pls_fit(   X, y, ncomp,   tol = 1e-8,   backend = c(\"auto\", \"arma\", \"bigmem\"),   scores  = c(\"none\", \"r\", \"big\"),   chunk_size = 10000L,   scores_name = \"scores\",   mode = c(\"auto\",\"pls1\",\"pls2\"),   scores_target = c(\"auto\",\"new\",\"existing\"),   scores_bm = NULL,   scores_backingfile = NULL,   scores_backingpath = NULL,   scores_descriptorfile = NULL,   scores_colnames = NULL,   return_scores_descriptor = FALSE )"},{"path":[]},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"dense-path-backend--arma","dir":"","previous_headings":"Backends & algorithms","what":"Dense path (backend = \"arma\")","title":"Partial Least Squares Regression Models with Big Matrices","text":"PLS1: fast dense solver (BLAS). Center X, Y, build XtX = XcᵀXc, XtY = XcᵀYc. Cholesky-whitened symmetric eigen solve; enforce symmetry add tiny ridge stabilize. Optional scores: T = Xc %*% W.","code":""},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"big-matrix-path-backend--bigmem","dir":"","previous_headings":"Backends & algorithms","what":"Big-matrix path (backend = \"bigmem\")","title":"Partial Least Squares Regression Models with Big Matrices","text":"Chunked /O big.matrix preallocated buffers. PLS1: streaming cross-products deflation; optional scores streamed chunk-wise sink. PLS2: chunked cross-products (XtX += BᵀB, XtY += BᵀY) + SIMPLS solver parity; optional score streaming: T = (X − μ) %*% W. paths enforce symmetry (0.5*(M+Mᵀ)) eigen use small ridge XtX stability.","code":""},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"scores-sinks-and-descriptors","dir":"","previous_headings":"","what":"Scores, sinks, and descriptors","title":"Partial Least Squares Regression Models with Big Matrices","text":"scores = \"none\" – don’t compute scores. scores = \"r\" – return -memory matrix. Provide sink via scores_target = \"existing\" + scores_bm (big.matrix descriptor), Let function create file-backed storage via scores_backingfile (+ optional scores_backingpath, scores_descriptorfile). scores_colnames – set column names scores. return_scores_descriptor = TRUE – adds fit$scores_descriptor scores big.matrix.","code":""},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"determinism-tests--reproducibility","dir":"","previous_headings":"","what":"Determinism (tests & reproducibility)","title":"Partial Least Squares Regression Models with Big Matrices","text":"tight parity tests, force 1 BLAS thread fix RNG:","code":"set.seed(1) if (requireNamespace(\"RhpcBLASctl\", quietly = TRUE)) {   RhpcBLASctl::blas_set_num_threads(1L) } else {   # Use env vars before BLAS loads in the session   Sys.setenv(     OMP_NUM_THREADS=\"1\",     OPENBLAS_NUM_THREADS=\"1\",     MKL_NUM_THREADS=\"1\",     VECLIB_MAXIMUM_THREADS=\"1\",     BLIS_NUM_THREADS=\"1\"   ) }"},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"performance-tuning","dir":"","previous_headings":"","what":"Performance tuning","title":"Partial Least Squares Regression Models with Big Matrices","text":"chunk_size: default 10000L. Apple Silicon, internal default larger (e.g., 16384) chunk_size == 0. Tune per dataset best GEMM throughput. Scores streaming: scores=\"big\", streaming avoids holding T fully RAM. Multi-thread BLAS: production, allow multi-thread BLAS; tests, use 1 thread.","code":""},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"optional-cblas-fast-path-in-place-gemm","dir":"","previous_headings":"","what":"Optional CBLAS fast path (in-place GEMM)","title":"Partial Least Squares Regression Models with Big Matrices","text":"Default: (CRAN-safe). optional -place accumulation (true beta = 1 CBLAS dgemm) available guarded compile-time checks. available enabled, package falls back automatically portable Armadillo path. Enable locally (Unix/macOS): src/Makevars, link BLAS/LAPACK R uses: macOS: code attempts <vecLib/cblas.h>; Linux/others: <cblas.h>. headers aren’t present, build silently falls back portable GEMM path. hardcode -lopenblas -framework Accelerate; use R’s variables. Windows: leave macro unless ’ve explicitly provided CBLAS headers/libs.","code":"R CMD INSTALL .   --configure-vars=\"PKG_CPPFLAGS='-DBIGPLSR_USE_CBLAS'\" PKG_LIBS += $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)"},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"development","dir":"","previous_headings":"","what":"Development","title":"Partial Least Squares Regression Models with Big Matrices","text":"Unit tests compare dense vs big-matrix backends PLS1/PLS2 tight tolerances. Vignettes examples keep datasets small; file-backed output uses tempdir().","code":""},{"path":"https://fbertran.github.io/bigPLSR/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Partial Least Squares Regression Models with Big Matrices","text":"use bigPLSR academic work, please cite package SIMPLS method de Jong (1993).","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/bigPLSR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bigPLSR-package — bigPLSR-package","title":"bigPLSR-package — bigPLSR-package","text":"Provides Partial least squares Regression big data. allows missing data explanatory variables. Repeated k-fold cross-validation models using various criteria. Bootstrap confidence intervals constructions also available.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/bigPLSR-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"bigPLSR-package — bigPLSR-package","text":"Maumy, M., Bertrand, F. (2023). PLS models extension big data. Joint Statistical Meetings (JSM 2023), Toronto, , Canada. Maumy, M., Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. BioC2023 — Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA. Poster. https://doi.org/10.7490/f1000research.1119546.1","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLSR/reference/bigPLSR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bigPLSR-package — bigPLSR-package","text":"Maintainer: Frederic Bertrand frederic.bertrand@lecnam.net (ORCID) Authors: Myriam Maumy myriam.maumy@ehesp.fr (ORCID)","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/bigPLSR-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bigPLSR-package — bigPLSR-package","text":"","code":"set.seed(314) library(bigPLSR) data(sim_data) head(sim_data) #>                    status         X1         X2         X3        X4         X5 #> 0.0013236229370777      1  0.5448667 -0.9205711  1.1017160 1.3558567  1.4346174 #> 0.193665925040523       1 -0.5641483  0.2733279  0.9731780 1.1232252  0.2652977 #> 0.0167866701431944      1  1.4921118  0.2598002 -1.5436997 0.1165158  1.2208183 #> 0.0584127055299712      1 -0.6430141 -0.9807448 -1.2294945 0.8006227  1.5492078 #> 0.732960708716205       1  0.1876928 -1.2571263  0.9016827 1.3562191 -1.6809553 #> 0.508483386474255       0 -0.6141516 -0.8162560  0.2633415 0.4188066  0.2791399 #>                            X6         X7         X8          X9        X10 #> 0.0013236229370777 -0.8727406  1.5161252  0.7801527 -0.53617252 -0.6990319 #> 0.193665925040523   1.5046047  0.9096495 -1.2200395 -1.57280359  0.8347194 #> 0.0167866701431944 -0.6451659  1.2515692  0.5867273 -0.20080821  0.7492891 #> 0.0584127055299712  1.2557210  0.6188920  0.7123894 -0.67379538 -1.2377412 #> 0.732960708716205   0.7304366 -1.1223302  0.9633307  0.14016470 -0.9996676 #> 0.508483386474255  -0.0538974 -0.1410697 -0.8637916  0.01669784  1.5589135"},{"path":"https://fbertran.github.io/bigPLSR/reference/bigmatrix-operations.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"methods extend base matrix multiplication operator (%*%) group generic Arithmetic big.matrix objects can interoperate base R matrices numeric scalars using high-performance routines provided bigalgebra.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/bigmatrix-operations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"","code":"# S4 method for class 'big.matrix,big.matrix' x %*% y  # S4 method for class 'matrix,big.matrix' x %*% y  # S4 method for class 'big.matrix,matrix' x %*% y  # S4 method for class 'big.matrix,big.matrix' Arith(e1, e2)  # S4 method for class 'big.matrix,matrix' Arith(e1, e2)  # S4 method for class 'matrix,big.matrix' Arith(e1, e2)  # S4 method for class 'numeric,big.matrix' Arith(e1, e2)  # S4 method for class 'big.matrix,numeric' Arith(e1, e2)"},{"path":"https://fbertran.github.io/bigPLSR/reference/bigmatrix-operations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"x, y Matrix operands supplied either big.matrix instances base R matrices, depending method signature. e1, e2 Numeric operands, may big.matrix objects, base R matrices, numeric scalars depending method signature.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/bigmatrix-operations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"Matrix multiplications dispatch bigalgebra::dgemm(), mixed arithmetic matrices relies bigalgebra::daxpy(), scalar/matrix combinations use bigalgebra::dadd() appropriate.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLSR/reference/bigmatrix-operations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"","code":"if (requireNamespace(\"bigmemory\", quietly = TRUE) &&     requireNamespace(\"bigalgebra\", quietly = TRUE)) {   x <- bigmemory::big.matrix(2, 2, init = 1)   y <- bigmemory::big.matrix(2, 2, init = 2)   x %*% y   x + y   x * 3 } #> An object of class \"big.matrix\" #> Slot \"address\": #> <pointer: 0x10f8ee840> #>"},{"path":"https://fbertran.github.io/bigPLSR/reference/bigscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — bigscale","title":"Title — bigscale","text":"Title","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/bigscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — bigscale","text":"","code":"bigscale(   formula = Surv(time = time, status = status) ~ .,   data,   norm.method = \"standardize\",   strata.size = 20,   batch.size = 1,   features.mean = NULL,   features.sd = NULL,   parallel.flag = FALSE,   num.cores = NULL,   bigmemory.flag = FALSE,   num.rows.chunk = 1e+06,   col.names = NULL,   type = \"short\" )"},{"path":"https://fbertran.github.io/bigPLSR/reference/bigscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — bigscale","text":"formula  data  norm.method  strata.size  batch.size  features.mean  features.sd  parallel.flag  num.cores  bigmemory.flag  num.rows.chunk  col.names  type","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/bigscale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Title — bigscale","text":"object scaler class time.indices: indices time variable cens.indices: indices censored variables features.indices: indices features time.sd: standard deviation time variable time.mean: mean time variable features.sd: standard deviation features features.mean: mean features nr: number rows nc: number columns col.names: columns names","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/bigscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Title — bigscale","text":"","code":"1+1 #> [1] 2"},{"path":"https://fbertran.github.io/bigPLSR/reference/plot_pls_biplot.html","id":null,"dir":"Reference","previous_headings":"","what":"PLS biplot — plot_pls_biplot","title":"PLS biplot — plot_pls_biplot","text":"PLS biplot","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/plot_pls_biplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PLS biplot — plot_pls_biplot","text":"","code":"plot_pls_biplot(object, comps = c(1L, 2L), scale_variables = 1, ...)"},{"path":"https://fbertran.github.io/bigPLSR/reference/plot_pls_biplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PLS biplot — plot_pls_biplot","text":"object fitted PLS model scores loadings. comps Components display. scale_variables Scaling factor applied variable loadings. ... Additional arguments passed graphics::plot().","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/plot_pls_individuals.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot individual scores — plot_pls_individuals","title":"Plot individual scores — plot_pls_individuals","text":"Plot individual scores","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/plot_pls_individuals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot individual scores — plot_pls_individuals","text":"","code":"plot_pls_individuals(object, comps = c(1L, 2L), labels = NULL, ...)"},{"path":"https://fbertran.github.io/bigPLSR/reference/plot_pls_individuals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot individual scores — plot_pls_individuals","text":"object fitted PLS model scores. comps Components plot (length two). labels Optional character vector point labels. ... Additional plotting parameters passed graphics::plot().","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/plot_pls_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot variable loadings — plot_pls_variables","title":"Plot variable loadings — plot_pls_variables","text":"Plot variable loadings","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/plot_pls_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot variable loadings — plot_pls_variables","text":"","code":"plot_pls_variables(object, comps = c(1L, 2L), ...)"},{"path":"https://fbertran.github.io/bigPLSR/reference/plot_pls_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot variable loadings — plot_pls_variables","text":"object fitted PLS model. comps Components display (length two). ... Additional plotting parameters passed graphics::plot().","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense.html","id":null,"dir":"Reference","previous_headings":"","what":"Single-response partial least squares regression (PLS1) — pls1_dense","title":"Single-response partial least squares regression (PLS1) — pls1_dense","text":"helpers expose optimised dense streaming solvers tailored partial least squares regression problems response consists single column. wrap high performance C++ routines shipped package provide user friendly entry point benchmarking available implementations.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Single-response partial least squares regression (PLS1) — pls1_dense","text":"","code":".harmonize_pls_result(res)  pls1_stream(   X,   y,   ncomp = 2L,   chunk_size = 1024L,   center = TRUE,   scale = FALSE,   center_y = TRUE,   scale_y = FALSE,   algorithm = c(\"simpls\", \"nipals\"),   return_big = FALSE )"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Single-response partial least squares regression (PLS1) — pls1_dense","text":"X bigmemory::big.matrix storing design matrix. y Numeric vector responses length nrow(X). ncomp Number latent components compute. chunk_size Number rows process per chunk. Must strictly positive. Smaller chunks reduce peak memory usage larger chunks may improve speed. center columns X centered? Defaults TRUE. scale columns X scaled unit variance? Defaults FALSE. center_y response centered? Defaults TRUE. scale_y response scaled unit variance? Defaults FALSE. algorithm Algorithm use fit. Either \"simpls\" \"nipals\". choosing \"simpls\", preprocessing options must remain default values. return_big Logical; TRUE, coefficients, scores loadings returned bigmemory::big.matrix objects. Defaults FALSE.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Single-response partial least squares regression (PLS1) — pls1_dense","text":"list containing regression coefficients, intercept, latent scores, loadings weights.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Single-response partial least squares regression (PLS1) — pls1_dense","text":"","code":"# \\donttest{ library(bigmemory) X <- as.big.matrix(matrix(rnorm(2000), nrow = 100)) y <- matrix(rnorm(100), ncol = 1) fit <- pls1_dense(X, y, ncomp = 3) str(fit) #> List of 15 #>  $ coefficients: num [1:20, 1] 0.1145 0.1132 -0.0814 -0.1989 0.1312 ... #>  $ intercept   : num -0.167 #>  $ x_weights   : num [1:20, 1:3] 0.0944 0.093 -0.2491 -0.1897 0.1397 ... #>  $ x_loadings  : num [1:20, 1:3] 0.03071 0.09135 -0.34936 -0.00304 0.07533 ... #>  $ y_loadings  : num [1:3, 1] 0.439 0.224 0.1 #>  $ x_means     : num [1:20] -0.0032 -0.07841 -0.16905 -0.08206 -0.00219 ... #>  $ y_mean      : num -0.091 #>  $ ncomp       : int 3 #>  $ weights     : num [1:20, 1:3] 0.0944 0.093 -0.2491 -0.1897 0.1397 ... #>  $ loadings    : num [1:20, 1:3] 0.03071 0.09135 -0.34936 -0.00304 0.07533 ... #>  $ x_center    : num [1:20] -0.0032 -0.07841 -0.16905 -0.08206 -0.00219 ... #>  $ y_center    : num -0.091 #>  $ x_scale     : NULL #>  $ y_scale     : NULL #>  $ scores      : NULL # }  # \\donttest{ library(bigmemory) X <- as.big.matrix(matrix(rnorm(2000), nrow = 100)) y <- matrix(rnorm(100), ncol = 1) fit <- pls1_stream(X, y, ncomp = 3) str(fit) #> List of 15 #>  $ coefficients: num [1:20, 1] -0.0634 -0.0947 0.0649 0.1416 -0.0312 ... #>  $ intercept   : num -0.0348 #>  $ x_weights   : num [1:20, 1:3] -0.0193 -0.2892 0.0764 0.0932 -0.0772 ... #>  $ x_loadings  : num [1:20, 1:3] 0.069 -0.3726 0.0123 -0.0112 -0.0616 ... #>  $ y_loadings  : num [1:3, 1] 0.405 0.194 0.074 #>  $ x_means     : num [1:20] -0.0804 -0.0878 -0.1322 0.104 0.1434 ... #>  $ y_mean      : num -0.0538 #>  $ ncomp       : int 3 #>  $ weights     : num [1:20, 1:3] -0.0193 -0.2892 0.0764 0.0932 -0.0772 ... #>  $ loadings    : num [1:20, 1:3] 0.069 -0.3726 0.0123 -0.0112 -0.0616 ... #>  $ x_center    : num [1:20] -0.0804 -0.0878 -0.1322 0.104 0.1434 ... #>  $ y_center    : num -0.0538 #>  $ x_scale     : NULL #>  $ y_scale     : NULL #>  $ scores      : NULL # }"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_a.html","id":null,"dir":"Reference","previous_headings":"","what":"Single-response partial least squares regression (PLS1) another implementation — pls1_dense_a","title":"Single-response partial least squares regression (PLS1) another implementation — pls1_dense_a","text":"helpers wrap high-performance C++ routines built top bigmemory bigalgebra infrastructure. pls1_dense_ya function performs standard PLS regression using NIPALS-style algorithm without copying data memory. pls1_stream_ya variant iterates data blocks makes possible handle --core datasets efficiently.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_a.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Single-response partial least squares regression (PLS1) another implementation — pls1_dense_a","text":"","code":"pls1_dense_a(   X,   y,   ncomp = 2L,   center = TRUE,   scale = FALSE,   tol = 1e-08,   max_iter = 100L,   algorithm = c(\"simpls\", \"nipals\"),   return_big = FALSE )  pls1_stream_a(   X,   y,   ncomp = 2L,   chunk_size = 1024L,   center = TRUE,   scale = FALSE,   tol = 1e-08,   algorithm = c(\"simpls\", \"nipals\"),   return_big = FALSE )"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_a.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Single-response partial least squares regression (PLS1) another implementation — pls1_dense_a","text":"X big.matrix object containing predictors. y Either big.matrix single column numeric vector response values. ncomp Number latent components extract. center Logical; predictors response centered. scale Logical; predictors response scaled unit variance fitting model. tol Numerical tolerance used detect convergence breakdown. max_iter Maximum number iterations internal solver (kept compatibility; solver adapts automatically convergence issues detected). algorithm Algorithm used compute PLS fit. Either \"simpls\" \"nipals\". SIMPLS backend supports default centering scaling configuration. return_big Logical; TRUE, coefficients, scores loadings returned bigmemory::big.matrix objects. Defaults FALSE. chunk_size Number rows processed time streaming backend.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_a.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Single-response partial least squares regression (PLS1) another implementation — pls1_dense_a","text":"list regression coefficients, intercept, latent scores, weights additional metadata.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_a.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Single-response partial least squares regression (PLS1) another implementation — pls1_dense_a","text":"","code":"# \\donttest{ library(bigmemory) X <- as.big.matrix(matrix(rnorm(2000), nrow = 100)) y <- as.big.matrix(matrix(rnorm(100), ncol = 1)) fit <- pls1_dense_a(X, y, ncomp = 3) str(fit) #> List of 16 #>  $ coefficients: num [1:20, 1] -0.0168 -0.1308 0.1621 0.1499 0.0418 ... #>  $ intercept   : num 0.222 #>  $ x_weights   : num [1:20, 1:3] -0.0027 -0.27846 0.35683 0.41143 0.00574 ... #>  $ x_loadings  : num [1:20, 1:3] 0.0337 -0.2535 0.3214 0.4333 -0.0755 ... #>  $ y_loadings  : num [1:3, 1] 0.3218 0.1069 0.0493 #>  $ x_means     : num [1:20] 0.0265 -0.0546 -0.0189 0.0167 -0.1192 ... #>  $ y_mean      : num 0.192 #>  $ ncomp       : int 3 #>  $ weights     : num [1:20, 1:3] -0.0027 -0.27846 0.35683 0.41143 0.00574 ... #>  $ loadings    : num [1:20, 1:3] 0.0337 -0.2535 0.3214 0.4333 -0.0755 ... #>  $ x_center    : num [1:20] 0.0265 -0.0546 -0.0189 0.0167 -0.1192 ... #>  $ y_center    : num 0.192 #>  $ x_scale     : NULL #>  $ y_scale     : NULL #>  $ scores      : NULL #>  $ call        : language pls1_dense_a(X = X, y = y, ncomp = 3) #>  - attr(*, \"class\")= chr [1:2] \"big_plsr\" \"list\" # }  # \\donttest{ library(bigmemory) X <- as.big.matrix(matrix(rnorm(2000), nrow = 100)) y <- as.big.matrix(matrix(rnorm(100), ncol = 1)) fit <- pls1_stream_a(X, y, ncomp = 3) str(fit) #> List of 17 #>  $ coefficients: num [1:20, 1] -0.2457 0.0752 0.1336 -0.2089 0.1301 ... #>  $ intercept   : num 0.0927 #>  $ x_weights   : num [1:20, 1:3] -0.2551 0.0453 0.2238 -0.2733 0.097 ... #>  $ x_loadings  : num [1:20, 1:3] -0.1273 -0.0333 0.2768 -0.195 -0.0221 ... #>  $ y_loadings  : num [1:3, 1] 0.579 0.197 0.1 #>  $ x_means     : num [1:20] -0.0705 -0.0676 0.0993 0.218 -0.1831 ... #>  $ y_mean      : num -0.0159 #>  $ ncomp       : int 3 #>  $ weights     : num [1:20, 1:3] -0.2551 0.0453 0.2238 -0.2733 0.097 ... #>  $ loadings    : num [1:20, 1:3] -0.1273 -0.0333 0.2768 -0.195 -0.0221 ... #>  $ x_center    : num [1:20] -0.0705 -0.0676 0.0993 0.218 -0.1831 ... #>  $ y_center    : num -0.0159 #>  $ x_scale     : NULL #>  $ y_scale     : NULL #>  $ scores      : NULL #>  $ chunk_size  : int 1024 #>  $ call        : language pls1_stream_a(X = X, y = y, ncomp = 3) #>  - attr(*, \"class\")= chr [1:2] \"big_plsr\" \"list\" # }"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_ya.html","id":null,"dir":"Reference","previous_headings":"","what":"Single-response partial least squares regression (PLS1) yet another implementation — pls1_dense_ya","title":"Single-response partial least squares regression (PLS1) yet another implementation — pls1_dense_ya","text":"Single-response partial least squares regression (PLS1) yet another implementation","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_ya.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Single-response partial least squares regression (PLS1) yet another implementation — pls1_dense_ya","text":"","code":"pls1_dense_ya(   x,   y,   ncomp,   tol = 1e-08,   algorithm = c(\"simpls\", \"nipals\"),   return_big = FALSE )  pls1_stream_ya(   x,   y,   ncomp,   chunk_size = 4096,   tol = 1e-08,   algorithm = c(\"simpls\", \"nipals\"),   return_big = FALSE )"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_ya.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Single-response partial least squares regression (PLS1) yet another implementation — pls1_dense_ya","text":"x, y Predictor response objects stored double precision bigmemory::big.matrix instances. response must contain single column. dense helper also accepts numeric vectors y converts transparently. dense routine copies predictors R matrix, streaming version accesses blocks. ncomp Number latent components extract. tol Convergence tolerance used estimating component. relevant dense variant. algorithm Algorithm used compute PLS fit. Either \"simpls\" \"nipals\". SIMPLS backend generally faster data fits memory. return_big Logical; TRUE, coefficients, scores loadings returned bigmemory::big.matrix objects. Defaults FALSE. chunk_size Number rows processed per block streaming variant.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_ya.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Single-response partial least squares regression (PLS1) yet another implementation — pls1_dense_ya","text":"list containing regression coefficients, intercept, loadings preprocessing statistics. structure matches output underlying C++ routines.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls1_dense_ya.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Single-response partial least squares regression (PLS1) yet another implementation — pls1_dense_ya","text":"","code":"# \\donttest{ library(bigmemory) X <- as.big.matrix(matrix(rnorm(2000), nrow = 100)) y <- as.big.matrix(matrix(rnorm(100), ncol = 1)) fit <- pls1_dense_ya(X, y, ncomp = 3) str(fit) #> List of 16 #>  $ coefficients: num [1:20, 1] 0.032576 0.063625 -0.000905 -0.055482 0.097963 ... #>  $ intercept   : num -0.135 #>  $ x_weights   : num [1:20, 1:3] -0.03604 0.16865 -0.00802 -0.01691 0.16181 ... #>  $ x_loadings  : num [1:20, 1:3] -0.108728 0.196599 0.000502 0.065538 0.092192 ... #>  $ y_loadings  : num [1:3, 1] 0.3892 0.119 0.0509 #>  $ x_means     : num [1:20] 4.29e-02 -6.20e-02 5.56e-05 -4.11e-04 1.79e-01 ... #>  $ y_mean      : num -0.1 #>  $ ncomp       : int 3 #>  $ weights     : num [1:20, 1:3] -0.03604 0.16865 -0.00802 -0.01691 0.16181 ... #>  $ loadings    : num [1:20, 1:3] -0.108728 0.196599 0.000502 0.065538 0.092192 ... #>  $ x_center    : num [1:20] 4.29e-02 -6.20e-02 5.56e-05 -4.11e-04 1.79e-01 ... #>  $ y_center    : num -0.1 #>  $ x_scale     : NULL #>  $ y_scale     : NULL #>  $ scores      : NULL #>  $ call        : language pls1_dense_ya(x = X, y = y, ncomp = 3) #>  - attr(*, \"class\")= chr [1:2] \"big_plsr\" \"list\" # }  # \\donttest{ library(bigmemory) X <- as.big.matrix(matrix(rnorm(2000), nrow = 100)) y <- as.big.matrix(matrix(rnorm(100), ncol = 1)) fit <- pls1_stream_ya(X, y, ncomp = 3) str(fit) #> List of 16 #>  $ coefficients: num [1:20, 1] 0.1189 0.0449 -0.0474 -0.0133 0.0545 ... #>  $ intercept   : num -0.215 #>  $ x_weights   : num [1:20, 1:3] 0.2465 0.1987 -0.2812 0.1544 0.0542 ... #>  $ x_loadings  : num [1:20, 1:3] 0.1625 0.2773 -0.3115 0.2517 0.0276 ... #>  $ y_loadings  : num [1:3, 1] 0.3138 0.1438 0.0843 #>  $ x_means     : num [1:20] 0.0192 0.1354 -0.0974 -0.19 -0.0393 ... #>  $ y_mean      : num -0.222 #>  $ ncomp       : int 3 #>  $ weights     : num [1:20, 1:3] 0.2465 0.1987 -0.2812 0.1544 0.0542 ... #>  $ loadings    : num [1:20, 1:3] 0.1625 0.2773 -0.3115 0.2517 0.0276 ... #>  $ x_center    : num [1:20] 0.0192 0.1354 -0.0974 -0.19 -0.0393 ... #>  $ y_center    : num -0.222 #>  $ x_scale     : NULL #>  $ y_scale     : NULL #>  $ scores      : NULL #>  $ call        : language pls1_stream_ya(x = X, y = y, ncomp = 3) #>  - attr(*, \"class\")= chr [1:2] \"big_plsr\" \"list\" # }"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls2_dense.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares regression for multi-response problems (PLS2) — pls2_dense","title":"Partial least squares regression for multi-response problems (PLS2) — pls2_dense","text":"Partial least squares regression multi-response problems (PLS2)","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls2_dense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares regression for multi-response problems (PLS2) — pls2_dense","text":"","code":"pls2_dense(   X,   Y,   ncomp,   center = TRUE,   scale = FALSE,   algorithm = c(\"simpls\", \"nipals\"),   return_big = FALSE )  pls2_stream(   X,   Y,   ncomp,   center = TRUE,   scale = FALSE,   chunk_size = 1024L,   algorithm = c(\"simpls\", \"nipals\"),   return_big = FALSE )"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls2_dense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares regression for multi-response problems (PLS2) — pls2_dense","text":"X bigmemory::big.matrix containing predictor variables. Y bigmemory::big.matrix storing multi-dimensional response. ncomp Number latent components compute. center inputs centered prior fitting? scale inputs scaled unit variance prior fitting? algorithm PLS backend use. Either \"simpls\" (default) \"nipals\". return_big Logical; TRUE, coefficients, scores loadings returned bigmemory::big.matrix objects. Defaults FALSE. chunk_size Number rows processed per block streaming variant.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls2_dense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial least squares regression for multi-response problems (PLS2) — pls2_dense","text":"list regression coefficients, intercept, weights, loadings preprocessing metadata.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_bootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrap confidence intervals for coefficients — pls_bootstrap","title":"Bootstrap confidence intervals for coefficients — pls_bootstrap","text":"Bootstrap confidence intervals coefficients","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_bootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrap confidence intervals for coefficients — pls_bootstrap","text":"","code":"pls_bootstrap(   X,   Y,   ncomp,   R = 100L,   algorithm = c(\"simpls\", \"nipals\"),   backend = \"arma\",   conf = 0.95,   seed = NULL )"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_bootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrap confidence intervals for coefficients — pls_bootstrap","text":"X Predictor matrix. Y Response matrix vector. ncomp Number components. R Number bootstrap replications. algorithm Backend algorithm. backend Backend argument passed fitting routine. conf Confidence level. seed Optional seed.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_bootstrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrap confidence intervals for coefficients — pls_bootstrap","text":"list bootstrap samples confidence intervals.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_cross_validate.html","id":null,"dir":"Reference","previous_headings":"","what":"K-fold or leave-one-out cross validation for PLS models — pls_cross_validate","title":"K-fold or leave-one-out cross validation for PLS models — pls_cross_validate","text":"K-fold leave-one-cross validation PLS models","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_cross_validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K-fold or leave-one-out cross validation for PLS models — pls_cross_validate","text":"","code":"pls_cross_validate(   X,   Y,   ncomp,   folds = 5L,   type = c(\"kfold\", \"loo\"),   algorithm = c(\"simpls\", \"nipals\"),   backend = \"arma\",   metrics = c(\"rmse\", \"mae\", \"r2\"),   seed = NULL )"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_cross_validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K-fold or leave-one-out cross validation for PLS models — pls_cross_validate","text":"X Predictor matrix. Y Response matrix vector. ncomp Number components evaluate. folds Number folds (ignored type = \"loo\"). type Either \"kfold\" (default) \"loo\". algorithm Backend algorithm: \"simpls\" \"nipals\". backend Backend passed pls_fit(). metrics Metrics compute (subset \"rmse\", \"mae\", \"r2\"). seed Optional seed reproducibility.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_cross_validate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"K-fold or leave-one-out cross validation for PLS models — pls_cross_validate","text":"list containing per-fold metrics summary across folds.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_cv_select.html","id":null,"dir":"Reference","previous_headings":"","what":"Select components from cross-validation results — pls_cv_select","title":"Select components from cross-validation results — pls_cv_select","text":"Select components cross-validation results","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_cv_select.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select components from cross-validation results — pls_cv_select","text":"","code":"pls_cv_select(cv_result, metric = c(\"rmse\", \"mae\", \"r2\"), minimise = NULL)"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_cv_select.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select components from cross-validation results — pls_cv_select","text":"cv_result Result returned pls_cross_validate(). metric Metric optimise. minimise Logical; whether metric minimised.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_cv_select.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select components from cross-validation results — pls_cv_select","text":"Selected number components.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Unified PLS fit with auto backend and selectable algorithm — pls_fit","title":"Unified PLS fit with auto backend and selectable algorithm — pls_fit","text":"Dispatches dense (Arm/BLAS) backend -memory matrices streaming big.matrix backend X (Y) big.matrix. Algorithm can chosen \"simpls\" (default) \"nipals\".","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unified PLS fit with auto backend and selectable algorithm — pls_fit","text":"","code":"pls_fit(   X,   y,   ncomp,   tol = 1e-08,   backend = c(\"auto\", \"arma\", \"bigmem\"),   mode = c(\"auto\", \"pls1\", \"pls2\"),   algorithm = c(\"auto\", \"simpls\", \"nipals\"),   scores = c(\"none\", \"r\", \"big\"),   chunk_size = 10000L,   scores_name = \"scores\",   scores_target = c(\"auto\", \"new\", \"existing\"),   scores_bm = NULL,   scores_backingfile = NULL,   scores_backingpath = NULL,   scores_descriptorfile = NULL,   scores_colnames = NULL,   return_scores_descriptor = FALSE )"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unified PLS fit with auto backend and selectable algorithm — pls_fit","text":"X numeric matrix bigmemory::big.matrix y numeric vector/matrix big.matrix ncomp number latent components tol numeric tolerance used core solver backend one \"auto\", \"arma\", \"bigmem\" mode one \"auto\", \"pls1\", \"pls2\" algorithm one \"auto\", \"simpls\", \"nipals\" scores one \"none\", \"r\", \"big\" chunk_size chunk size bigmem backend scores_name name dense scores (output big.matrix) scores_target one \"auto\", \"new\", \"existing\" scores_bm optional existing big.matrix descriptor scores scores_colnames optional character vector score column names return_scores_descriptor logical; TRUE scores big.matrix, add $scores_descriptor scores_backingfile/backingpath/descriptorfile file-backed sink args","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unified PLS fit with auto backend and selectable algorithm — pls_fit","text":"list coefficients, intercept, weights, loadings, means, optionally $scores.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_select_components.html","id":null,"dir":"Reference","previous_headings":"","what":"Component selection via information criteria — pls_select_components","title":"Component selection via information criteria — pls_select_components","text":"Component selection via information criteria","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_select_components.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Component selection via information criteria — pls_select_components","text":"","code":"pls_select_components(   object,   X,   Y,   criteria = c(\"aic\", \"bic\"),   max_comp = NULL )"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_select_components.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component selection via information criteria — pls_select_components","text":"object fitted PLS model. X Training design matrix. Y Training response matrix vector. criteria Character vector specifying criteria compute. max_comp Maximum number components consider.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_select_components.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Component selection via information criteria — pls_select_components","text":"list per-component table selected components.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Naive sparsity control by coefficient thresholding — pls_threshold","title":"Naive sparsity control by coefficient thresholding — pls_threshold","text":"Naive sparsity control coefficient thresholding","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Naive sparsity control by coefficient thresholding — pls_threshold","text":"","code":"pls_threshold(object, threshold)"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Naive sparsity control by coefficient thresholding — pls_threshold","text":"object fitted PLS model. threshold Values absolute magnitude set zero.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Naive sparsity control by coefficient thresholding — pls_threshold","text":"modified copy object thresholded coefficients.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_vip.html","id":null,"dir":"Reference","previous_headings":"","what":"Variable importance in projection (VIP) scores — pls_vip","title":"Variable importance in projection (VIP) scores — pls_vip","text":"Variable importance projection (VIP) scores","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_vip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variable importance in projection (VIP) scores — pls_vip","text":"","code":"pls_vip(object, comps = NULL)"},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_vip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variable importance in projection (VIP) scores — pls_vip","text":"object fitted PLS model. comps Components used compute VIP scores. Defaults available components.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/pls_vip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variable importance in projection (VIP) scores — pls_vip","text":"named numeric vector VIP scores.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/predict.big_plsr.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for big_plsr objects — predict.big_plsr","title":"Predict method for big_plsr objects — predict.big_plsr","text":"Predict method big_plsr objects","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/predict.big_plsr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for big_plsr objects — predict.big_plsr","text":"","code":"# S3 method for class 'big_plsr' predict(object, newdata, ncomp = NULL, type = c(\"response\", \"scores\"), ...)"},{"path":"https://fbertran.github.io/bigPLSR/reference/predict.big_plsr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for big_plsr objects — predict.big_plsr","text":"object fitted PLS model produced pls_fit(). newdata Matrix bigmemory::big.matrix predictor values. ncomp Number components use prediction. type Either \"response\" (default) \"scores\". ... Unused, compatibility generic.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/predict.big_plsr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for big_plsr objects — predict.big_plsr","text":"Predicted responses component scores.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/sim_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated dataset — sim_data","title":"Simulated dataset — sim_data","text":"dataset provides explantory variables simulations censoring status.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/sim_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated dataset — sim_data","text":"data frame 1000 observations following 11 variables. status binary vector X1 numeric vector X2 numeric vector X3 numeric vector X4 numeric vector X5 numeric vector X6 numeric vector X7 numeric vector X8 numeric vector X9 numeric vector X10 numeric vector","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/sim_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated dataset — sim_data","text":"TODO.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/sim_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated dataset — sim_data","text":"","code":"# \\donttest{ data(sim_data) X_sim_data_train <- sim_data[1:800,2:11] C_sim_data_train <- sim_data$status[1:800] X_sim_data_test <- sim_data[801:1000,2:11] C_sim_data_test <- sim_data$status[801:1000] rm(X_sim_data_train,C_sim_data_train,X_sim_data_test,C_sim_data_test) # }"},{"path":"https://fbertran.github.io/bigPLSR/reference/summary.big_plsr.html","id":null,"dir":"Reference","previous_headings":"","what":"Summaries for big_plsr objects — summary.big_plsr","title":"Summaries for big_plsr objects — summary.big_plsr","text":"Summaries big_plsr objects","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/summary.big_plsr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summaries for big_plsr objects — summary.big_plsr","text":"","code":"# S3 method for class 'big_plsr' summary(object, X = NULL, Y = NULL, ...)"},{"path":"https://fbertran.github.io/bigPLSR/reference/summary.big_plsr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summaries for big_plsr objects — summary.big_plsr","text":"object fitted PLS model. X Optional design matrix recompute reconstruction metrics. Y Optional response matrix/vector. ... Unused.","code":""},{"path":"https://fbertran.github.io/bigPLSR/reference/summary.big_plsr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summaries for big_plsr objects — summary.big_plsr","text":"object class summary.big_plsr.","code":""},{"path":"https://fbertran.github.io/bigPLSR/news/index.html","id":"bigplsr-040","dir":"Changelog","previous_headings":"","what":"bigPLSR 0.4.0","title":"bigPLSR 0.4.0","text":"Maintainer email update Added unit tests","code":""},{"path":"https://fbertran.github.io/bigPLSR/news/index.html","id":"bigplsr-030","dir":"Changelog","previous_headings":"","what":"bigPLSR 0.3.0","title":"bigPLSR 0.3.0","text":"Code update","code":""},{"path":"https://fbertran.github.io/bigPLSR/news/index.html","id":"bigplsr-020","dir":"Changelog","previous_headings":"","what":"bigPLSR 0.2.0","title":"bigPLSR 0.2.0","text":"Improving code help pages","code":""},{"path":"https://fbertran.github.io/bigPLSR/news/index.html","id":"bigplsr-010","dir":"Changelog","previous_headings":"","what":"bigPLSR 0.1.0","title":"bigPLSR 0.1.0","text":"Implementing gpls, sgpls based models","code":""},{"path":"https://fbertran.github.io/bigPLSR/news/index.html","id":"bigplsr-001","dir":"Changelog","previous_headings":"","what":"bigPLSR 0.0.1","title":"bigPLSR 0.0.1","text":"Package creation","code":""}]
